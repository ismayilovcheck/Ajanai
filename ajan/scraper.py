"""
Ajan Web Scraper ModÃ¼lÃ¼
Web sitelerini tarayan ve gelir fÄ±rsatlarÄ±nÄ± toplayan modÃ¼l
"""

import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
import time
from config import AjanConfig

class AjanScraper:
    """Ajan iÃ§in web sitelerini tarayan ve veri Ã§eken sÄ±nÄ±f"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': AjanConfig.USER_AGENT,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
            'Accept-Language': 'tr-TR,tr;q=0.9,en-US;q=0.8,en;q=0.7'
        })
        self.timeout = AjanConfig.REQUEST_TIMEOUT
        print("âœ“ AjanScraper baÅŸlatÄ±ldÄ±")
    
    def fetch_page(self, url: str) -> Optional[BeautifulSoup]:
        """Bir web sayfasÄ±nÄ± Ã§eker ve BeautifulSoup nesnesi dÃ¶ndÃ¼rÃ¼r"""
        try:
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            return BeautifulSoup(response.content, 'lxml')
        except requests.RequestException as e:
            print(f"âš  Ajan - Hata: {url} Ã§ekilemedi - {str(e)}")
            return None
    
    def scrape_freelance_opportunities(self, site_url: str) -> List[Dict]:
        """Freelance sitelerinden fÄ±rsatlarÄ± Ã§eker"""
        opportunities = []
        print(f"  â†’ {site_url} taranÄ±yor...")
        
        soup = self.fetch_page(site_url)
        if not soup:
            return opportunities
        
        # TODO: Siteye Ã¶zel scraping mantÄ±ÄŸÄ± buraya eklenecek
        # Ã–rnek yapÄ±:
        # projects = soup.find_all('div', class_='project-item')
        # for project in projects:
        #     opportunities.append({
        #         'title': project.find('h3').text.strip(),
        #         'description': project.find('p').text.strip(),
        #         'payment': project.find('span', class_='amount').text.strip(),
        #         'source': site_url
        #     })
        
        return opportunities
    
    def scrape_survey_opportunities(self, site_url: str) -> List[Dict]:
        """Anket platformlarÄ±ndan fÄ±rsatlarÄ± Ã§eker"""
        opportunities = []
        print(f"  â†’ {site_url} taranÄ±yor...")
        
        soup = self.fetch_page(site_url)
        if not soup:
            return opportunities
        
        # TODO: Siteye Ã¶zel scraping mantÄ±ÄŸÄ± buraya eklenecek
        
        return opportunities
    
    def scrape_microtask_opportunities(self, site_url: str) -> List[Dict]:
        """Mikro gÃ¶rev sitelerinden fÄ±rsatlarÄ± Ã§eker"""
        opportunities = []
        print(f"  â†’ {site_url} taranÄ±yor...")
        
        soup = self.fetch_page(site_url)
        if not soup:
            return opportunities
        
        # TODO: Siteye Ã¶zel scraping mantÄ±ÄŸÄ± buraya eklenecek
        
        return opportunities
    
    def search_all_opportunities(self) -> List[Dict]:
        """Ajan tÃ¼m platformlarÄ± tarar ve fÄ±rsatlarÄ± toplar"""
        all_opportunities = []
        
        print("\nðŸ“Š Freelance siteleri taranÄ±yor...")
        for site in AjanConfig.FREELANCE_SITES:
            opps = self.scrape_freelance_opportunities(site)
            all_opportunities.extend(opps)
            time.sleep(2)  # Rate limiting
        
        print("\nðŸ“‹ Anket platformlarÄ± taranÄ±yor...")
        for site in AjanConfig.ANKET_PLATFORMLARI:
            opps = self.scrape_survey_opportunities(site)
            all_opportunities.extend(opps)
            time.sleep(2)
        
        print("\nðŸ”§ Mikro gÃ¶rev siteleri taranÄ±yor...")
        for site in AjanConfig.MIKRO_GOREV_SITELERI:
            opps = self.scrape_microtask_opportunities(site)
            all_opportunities.extend(opps)
            time.sleep(2)
        
        return all_opportunities