import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Optional
import time
from config import AjanConfig

class AjanScraper:
    """Veb saytlarÄ± skan edÉ™n vÉ™ mÉ™lumatlarÄ± Ã§É™kÉ™n sinif"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': AjanConfig.USER_AGENT,
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
        })
        self.timeout = AjanConfig.REQUEST_TIMEOUT
        print("âœ“ AjanScraper (Tap.az DÉ™stÉ™yi ilÉ™) baÅŸladÄ±ldÄ±")
    
    def fetch_page(self, url: str) -> Optional[BeautifulSoup]:
        try:
            time.sleep(1.5) # SaytÄ±n bloklamamasÄ± Ã¼Ã§Ã¼n gÃ¶zlÉ™mÉ™
            response = self.session.get(url, timeout=self.timeout)
            response.raise_for_status()
            # Parser xÉ™tasÄ±nÄ±n qarÅŸÄ±sÄ±nÄ± almaq Ã¼Ã§Ã¼n
            try:
                return BeautifulSoup(response.content, 'lxml')
            except:
                return BeautifulSoup(response.content, 'html.parser')
        except Exception as e:
            print(f"âš  XÉ™ta: {url} Ã§É™kilÉ™ bilmÉ™di - {str(e)}")
            return None

    def scrape_tap_az(self, url: str) -> List[Dict]:
        """Tap.az-dan elanlarÄ± Ã§É™kir"""
        opportunities = []
        soup = self.fetch_page(url)
        if not soup: return opportunities

        # Tap.az elan konteynerlÉ™ri: 'products-i'
        items = soup.find_all('div', class_='products-i')
        
        for item in items:
            try:
                title_elem = item.find('div', class_='products-name')
                price_elem = item.find('span', class_='price-cur')
                link_elem = item.find('a', class_='products-link')
                
                if title_elem and price_elem:
                    title = title_elem.text.strip()
                    price = price_elem.parent.text.strip() # QiymÉ™t vÉ™ valyuta
                    link = "https://tap.az" + link_elem['href']
                    
                    opportunities.append({
                        'title': title,
                        'description': f"Tap.az yerli fÃ¼rsÉ™t: {title}",
                        'payment': price,
                        'source': 'Tap.az',
                        'url': link,
                        'type': 'local',
                        'difficulty': 'MÃ¼É™yyÉ™n edilmÉ™yib',
                        'duration': 'DanÄ±ÅŸÄ±q asÄ±lÄ±dÄ±r'
                    })
            except Exception as e:
                continue
        return opportunities

    def search_all_opportunities(self) -> List[Dict]:
        """BÃ¼tÃ¼n platformalarÄ± tarayÄ±r"""
        all_opportunities = []
        
        # ğŸ‡¦ğŸ‡¿ Ä°lk olaraq yerli Tap.az elanlarÄ±nÄ± Ã§É™kirik
        print("\nğŸ‡¦ğŸ‡¿ Tap.az taranÄ±r...")
        for site in AjanConfig.AZ_SITELERI:
            opps = self.scrape_tap_az(site)
            all_opportunities.extend(opps)
            
        # ÆgÉ™r Tap.az-dan heÃ§ nÉ™ tapÄ±lmasa, demo mÉ™lumatlarÄ± qaytarmamaq Ã¼Ã§Ã¼n 
        # burada boÅŸ siyahÄ± yoxlamasÄ± edÉ™ bilÉ™rsÉ™n.
        
        return all_opportunities
